[{"authors":["admin"],"categories":null,"content":"I am an assistant professor of business analytics in HKU Business School. My research interests include stochastic simulation, decision analytics, statistical learning, and mathematical finance.\nAs an academic, my goal is to identify and study key structures in stochastic systems to deliver better decisions, increasing efficiency and reducing risk of the operations. The growing data availability and computing power provide vast opportunities to design new statistical tools to facilitate the decision-making process. In this regard, I aim to develop general methodologies in statistics, stochastics, and simulation for decision analytics and integrate these tools to solve real-world challenges.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://xiaoweiz.github.io/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"I am an assistant professor of business analytics in HKU Business School. My research interests include stochastic simulation, decision analytics, statistical learning, and mathematical finance.\nAs an academic, my goal is to identify and study key structures in stochastic systems to deliver better decisions, increasing efficiency and reducing risk of the operations.","tags":null,"title":"","type":"authors"},{"authors":["Jin Li","Ye Luo","Xiaowei Zhang"],"categories":[],"content":"","date":1613383604,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613383604,"objectID":"e7e8e9c13cea81d58ca650840f7a87fc","permalink":"https://xiaoweiz.github.io/publication/causal-rl/","publishdate":"2021-02-15T18:06:44+08:00","relpermalink":"/publication/causal-rl/","section":"publication","summary":"In the standard data analysis framework, data is first collected (once for all), and then data analysis is carried out. Moreover, the data-generating process is typically assumed to be exogenous. This approach is natural when the data analyst has no impact on how the data is generated. The advancement of digital technology, however, has facilitated firms to learn from data and make decisions at the same time. As these decisions generate new data, the data analyst---a business manager or an algorithm---also becomes the data generator. In this article, we formulate the problem as a Markov decision process (MDP) and show that the interaction generates a new type of bias---reinforcement bias---that exacerbates the endogeneity problem in static data analysis. When the data are independent and identically distributed, we embed the instrumental variable (IV) approach in the stochastic gradient descent  algorithm to correct for the bias. For general MDP problems, we propose a class of IV-based reinforcement learning (RL)     algorithms to correct for the bias. We establish asymptotic properties of the algorithms by incorporating them into two-timescale stochastic approximation (SA). Our formulation requires unbounded state space and more importantly, Markovian noise. Therefore, standard techniques in RL and SA literature, which rely on boundedness of the state space and martingale-difference structure of the noise, do not apply. We develop new techniques to establish finite-time risk bounds, finite-time bounds for trajectory stability, and asymptotic distribution of a class of IV-RL algorithms.","tags":["reinforcement learning","Markov decision process","Q-learning","instrumental variable","stochastic approximation"],"title":"Causal Reinforcement Learning: An Instrumental Variable Approach","type":"publication"},{"authors":[],"categories":[],"content":"In the standard data analysis framework, data is first collected (once for all), and then data analysis is carried out. Moreover, the data-generating process is typically assumed to be exogenous. This approach is natural when the data analyst has no impact on how the data is generated. The advancement of digital technology, however, has facilitated firms to learn from data and make decisions at the same time. As these decisions generate new data, the data analyst\u0026mdash;a business manager or an algorithm\u0026mdash;also becomes the data generator. This interaction generates a new type of bias\u0026mdash;reinforcement bias\u0026mdash;that exacerbates the endogeneity problem in static data analysis. Causal inference techniques ought to be incorporated into reinforcement learning to address such issues.\n","date":1613305356,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613305356,"objectID":"287abba6aa4e84575d494aafc05ce55e","permalink":"https://xiaoweiz.github.io/project/causal-reinforcement-learning/","publishdate":"2021-02-14T20:22:36+08:00","relpermalink":"/project/causal-reinforcement-learning/","section":"project","summary":"Sequential decision-making driven by causal discovery","tags":[],"title":"Causal Reinforcement Learning","type":"project"},{"authors":["Haihui Shen","L. Jeff Hong","Xiaowei Zhang"],"categories":[],"content":"","date":1613124404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613124404,"objectID":"07951d4d0447cd15562eb3c132e14146","permalink":"https://xiaoweiz.github.io/publication/contextual-selection/","publishdate":"2020-07-16T21:44:00+08:00","relpermalink":"/publication/contextual-selection/","section":"publication","summary":"We consider a ranking and selection problem in the context of personalized decision making, where the best alternative is not universal but varies as a function of observable covariates. The goal of ranking and selection with covariates (R\u0026S-C) is to use sampling to compute a decision rule that can specify the best alternative with certain statistical guarantee for each subsequent individual after observing his or her covariates. A linear model is proposed to capture the relationship between the mean performance of an alternative and the covariates. Under the indifference-zone formulation, we develop two-stage procedures for both homoscedastic and heteroscedastic sampling errors, respectively, and prove their statistical validity, which is defined in terms of probability of correct selection. We also generalize the well-known slippage configuration, and prove that the generalized slippage configuration is the least favorable configuration of our procedures. Extensive numerical experiments are conducted to investigate the performance of the proposed procedures. Finally, we demonstrate the usefulness of R\u0026S-C via a case study of selecting the best treatment regimen in the prevention of esophageal cancer. We find that by leveraging disease-related personal information, R\u0026S-C can improve substantially the expected quality-adjusted life years for some groups of patients through providing patient-specific treatment regimen.","tags":["ranking and selection","covariates","personalized medicine"],"title":"Ranking and Selection with Covariates for Personalized Decision Making","type":"publication"},{"authors":[],"categories":null,"content":"","date":1607138100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607138100,"objectID":"6d12396b86729ac0109b2ee78f0e565c","permalink":"https://xiaoweiz.github.io/talk/wops20/","publishdate":"2021-02-14T20:31:57+08:00","relpermalink":"/talk/wops20/","section":"talk","summary":"Stochastic kriging has been widely employed for simulation metamodeling to predict the response surface of a complex simulation model. However, its use is limited to cases where the design space is low-dimensional, because the number of design points required for stochastic kriging to produce accurate prediction, in general, grows exponentially in the dimension of the design space. The large sample size results in both a prohibitive sample cost for running the simulation model and a severe computational challenge due to the need of inverting large covariance matrices. Based on tensor Markov kernels and sparse grid experimental designs, we develop a novel methodology that dramatically alleviates the curse of dimensionality. We show that the sample complexity of the proposed methodology grows very mildly in the dimension, even under model misspecification. We also develop fast algorithms that compute stochastic kriging in its exact form without any approximation schemes. We demonstrate via extensive numerical experiments that our methodology can handle problems with a design space of hundreds of dimensions, improving both prediction accuracy and computational efficiency by orders of magnitude relative to typical alternative methods in practice.","tags":["simulation metamodeling","stochastic kriging","Gaussian process","tensor Markov kernel","sparse grid","experimental design","matrix inversion","high-dimensional inputs"],"title":"Sample and Computationally Efficient Simulation Metamodeling in High Dimensions","type":"talk"},{"authors":["Liang Ding","Xiaowei Zhang"],"categories":[],"content":"","date":1602583604,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602583604,"objectID":"179a0d4185564337e4622dbcbe1680de","permalink":"https://xiaoweiz.github.io/publication/high-dim-kriging/","publishdate":"2020-10-13T22:01:54+08:00","relpermalink":"/publication/high-dim-kriging/","section":"publication","summary":"Stochastic kriging has been widely employed for simulation metamodeling to predict the response surface of a complex simulation model. However, its use is limited to cases where the design space is low-dimensional, because the number of design points required for stochastic kriging to produce accurate prediction, in general, grows exponentially in the dimension of the design space. The large sample size results in both a prohibitive sample cost for running the simulation model and a severe computational challenge due to the need of inverting large covariance matrices. Based on tensor Markov kernels and sparse grid experimental designs, we develop a novel methodology that dramatically alleviates the curse of dimensionality. We show that the sample complexity of the proposed methodology grows very mildly in the dimension, even under model misspecification. We also develop fast algorithms that compute stochastic kriging in its exact form without any approximation schemes. We demonstrate via extensive numerical experiments that our methodology can handle problems with a design space of hundreds of dimensions, improving both prediction accuracy and computational efficiency by orders of magnitude relative to typical alternative methods in practice.","tags":["simulation metamodeling","stochastic kriging","Gaussian process","tensor Markov kernel","sparse grid","experimental design","matrix inversion","high-dimensional inputs"],"title":"Sample and Computationally Efficient Simulation Metamodeling in High Dimensions","type":"publication"},{"authors":["Xiaowei Zhang","Haihui Shen","L. Jeff Hong","Liang Ding"],"categories":[],"content":"","date":1594825901,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594825901,"objectID":"3713ba119ec8cb6d798bdcf459f6f02a","permalink":"https://xiaoweiz.github.io/publication/kg-contextual-selection/","publishdate":"2020-07-15T23:11:41+08:00","relpermalink":"/publication/kg-contextual-selection/","section":"publication","summary":"Knowledge gradient is a design principle for developing Bayesian sequential sampling policies to consider in this paper the ranking and selection problem in the presence of covariates, where the best alternative is not universal but depends on the covariates. In this context, we prove that under minimal assumptions, the sampling policy based on knowledge gradient is consistent, in the sense that following the policy the best alternative as a function of the covariates will be identiﬁed almost surly as the number of samples grows. We also propose a stochastic gradient ascent algorithm for computing the sampling policy and demonstrate its performance via numerical experiments.","tags":["knowledge gradient","ranking and selection","covariates","Gaussian process","covariance function","reproducing kernel Hilbert space"],"title":"Knowledge Gradient for Selection with Covariates: Consistency and Computation","type":"publication"},{"authors":["Weiwei Fan","L. Jeff Hong","Xiaowei Zhang"],"categories":[],"content":"","date":1579093911,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579093911,"objectID":"d0f5ce3358a72cfe243901194fea5d61","permalink":"https://xiaoweiz.github.io/publication/robust-selection/","publishdate":"2019-06-03T21:11:51+08:00","relpermalink":"/publication/robust-selection/","section":"publication","summary":"Specifying a proper input distribution is often a challenging task in simulation modeling. In practice, there may be multiple plausible distributions that can fit the input data reasonably well, especially when the data volume is not large. In this paper, we consider the problem of selecting the best from a finite set of simulated alternatives, in the presence of such input uncertainty. We model such uncertainty by an ambiguity set consisting of a finite number of plausible input distributions, and aim to select the alternative with the best worst-case mean performance over the ambiguity set. We refer to this problem as robust selection of the best (RSB). To solve the RSB problem, we develop a two-stage selection procedure and a sequential selection procedure; we then prove that both procedures can achieve at least a user-specified probability of correct selection under mild conditions. Extensive numerical experiments are conducted to investigate the computational efficiency of the two procedures. Finally, we apply the RSB approach to study a queueing system's staffing problem using synthetic data and an appointment scheduling problem using real data from a large hospital in China. We find that the RSB approach can generate decisions significantly better than other widely used approaches.","tags":["ranking and selection","robust optimization","appointment scheduling","input uncertainty"],"title":"Distributionally Robust Selection of the Best","type":"publication"},{"authors":[],"categories":[],"content":"Modern stochastic systems often have a sophisticated structure. Their performance is generally not an analytical function of the decision variables, but a complex surface that can only be evaluated at discrete locations via noisy samples. Since the sampling process is often expensive, we would like to identify the optimal decision with minimal samples. Optimization via sampling is essentially a trade-off between exploitation, which tends to sample more at \u0026lsquo;\u0026lsquo;promising\u0026rsquo;\u0026rsquo; areas, and exploration, which tends to sample more at \u0026lsquo;\u0026lsquo;uncharted\u0026rsquo;\u0026rsquo; areas. Hyperparameter tuning in machine learning is a modernized example of this paradigm of optimization.\n","date":1559568385,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559568385,"objectID":"f2032f28299a1aeb7c517218acb73bfb","permalink":"https://xiaoweiz.github.io/project/sampling-based-optimization/","publishdate":"2019-06-03T21:26:25+08:00","relpermalink":"/project/sampling-based-optimization/","section":"project","summary":"Optimizing unknown functions that can only be learned via expensive sampling","tags":[],"title":"Sampling-Based Optimization","type":"project"},{"authors":[],"categories":[],"content":"Simulation models are extensively used in a great variety of areas including health care, finance, manufacturing, logistics, supply chain management, telecommunication, etc. to facilitate related decision making processes. However, simulation models are usually computationally expensive to execute, which severely restricts the usefulness of simulation in settings such as real-time decision making and system optimization. Metamodeling is technique that has been actively developed in the simulation community, in order to alleviate the inefficiency issue. The basic idea is that the user executes the simulation model only at a small number of carefully selected \u0026lsquo;\u0026lsquo;design points\u0026rsquo;\u0026rsquo;. A metamodel, or model of the simulation model, can be built to approximate the true response surface by properly interpolating the simulation outputs. The response at other design points is then predicted by the metamodel without running simulation at all, thereby substantially reducing the computational costs. The metamodel can be used to efficiently search for the optimal values of the design variables, even in real time.\n","date":1559564556,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559564556,"objectID":"15db86e89d8b557d9de26ae279df8ecd","permalink":"https://xiaoweiz.github.io/project/simulation-metamodeling/","publishdate":"2019-06-03T20:22:36+08:00","relpermalink":"/project/simulation-metamodeling/","section":"project","summary":"A model of simulation models","tags":[],"title":"Simulation Metamodeling","type":"project"},{"authors":[],"categories":[],"content":"Operational decision making in service systems often depends largely on the characterization of the random fluctuations involved. Exogenous arrivals represent a primary source of uncertainty and their stochastic behavior needs to be modeled carefully. Recent empirical studies demonstrate that the arrival data usually exhibits a dynamics that is substantially more sophisticated than the Poisson process model (and even the renewal process model), both of which are the underlying assumption of a wide variety of results in the queueing theory.\n","date":1559561136,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559561136,"objectID":"5be4666e3368d2b7ff3b0d4132727b65","permalink":"https://xiaoweiz.github.io/project/arrival-data-modeling/","publishdate":"2019-06-03T19:25:36+08:00","relpermalink":"/project/arrival-data-modeling/","section":"project","summary":"Modeling, forecasting, and analysis of arrival data of large service systems","tags":[],"title":"Arrival Data Modeling","type":"project"},{"authors":null,"categories":null,"content":"Affine processes constitute an important class of continuous time stochastic models that are widely used in finance and econometrics due to their modeling flexibility and computational/analytical tractability. This class of models include affine jump-diffusions (AJDs) and affine point processes (APPs). Examples of AJDs include the Ornstein-Uhlenbeck (OU) process (i.e. the Vasicek model), the square-root diffusion process, (i.e. the Cox-Ingersoll-Ross model), and the Heston stochastic volatility model, all of which are classical models in dynamic asset pricing. On the other hand, examples of APPs include the Hawkes process and its multidimensional extensions, which was applied in credit risk modeling and has lately found important applications in high-frequency trading.\n","date":1559550295,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559550295,"objectID":"8931cfc8a061183edb21ebe6ac3e68b3","permalink":"https://xiaoweiz.github.io/project/mathematical-finance/","publishdate":"2019-06-03T16:24:55+08:00","relpermalink":"/project/mathematical-finance/","section":"project","summary":"Asymptotic analysis of a popular class of tractable financial models","tags":null,"title":"Mathematical Finance","type":"project"},{"authors":[],"categories":[],"content":"Rare events refer to those that occur with small probabilities but would have substantial impact when they do. Examples include meltdown of a communication network and credit default of a large financial institution. A typical approach to rare event analysis is the large deviations (LD) technique, which characterizes the rare event probability up to the correct logarithmic order of magnitude. To obtain a more accurate estimate, one often resorts to Monte Carlo (MC) simulation. But using the plain vanilla MC to estimate small probabilities requires an enormous number of samples due to the fact that the variance of the MC estimator is orders of magnitude larger than its mean. The LD technique can facilitate to develop importance sampling schemes that reduce the variance of the MC estimator dramatically.\n","date":1559534467,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559534467,"objectID":"54d870c8c8f1861ff438d15674404f83","permalink":"https://xiaoweiz.github.io/project/rare-event-analysis/","publishdate":"2019-06-03T12:01:07+08:00","relpermalink":"/project/rare-event-analysis/","section":"project","summary":"Characterizing small probabilities","tags":[],"title":"Rare Event Analysis","type":"project"},{"authors":[],"categories":null,"content":"","date":1559359800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559359800,"objectID":"179e0d506b7d9fb9588a92a86a4f8826","permalink":"https://xiaoweiz.github.io/talk/mostlyom19/","publishdate":"2019-06-03T20:31:57+08:00","relpermalink":"/talk/mostlyom19/","section":"talk","summary":"A typical decision making problem in practice is to select the best from a collection of alternatives. The value of each alternative, however, is unknown and can only be learned via expensive sampling. Motivated by the emerging popularity of personalized decision making in various areas including healthcare and e-commerce, we study the selection problem in the presence of contextual information, where the best alternative is not universal but depends on certain covariates. Given a limited sampling budget, we propose an adaptive sampling strategy to efficiently learn the decision rule that specifies the best alternative for a given value of the covariates. The sampling strategy is developed via a nonparametric Bayesian approach and is shown to be asymptotically optimal. We demonstrate the usefulness of our methodology via a case study in personalized medicine for selecting the best cancer treatment regimen.","tags":["ranking and selection","knowledge gradient","covariates","Bayesian","Gaussian process"],"title":"Bayesian Sequential Learning for Contextual Selection","type":"talk"},{"authors":["Haojun Huo","Xiaowei Zhang","Zeyu Zheng"],"categories":[],"content":"","date":1544609204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544609204,"objectID":"b238b57cffd08950a50af8e476154216","permalink":"https://xiaoweiz.github.io/publication/scalable-kriging-gradients-wsc/","publishdate":"2019-06-03T21:58:21+08:00","relpermalink":"/publication/scalable-kriging-gradients-wsc/","section":"publication","summary":"It is known that incorporating gradient information can significantly enhance the prediction accuracy of stochastic kriging. However, such an enhancement cannot be scaled trivially to high-dimensional design space, since one needs to invert a large covariance matrix that captures the spatial correlations between the responses and the gradient estimates at the design points. Not only is the inversion computationally inefficient, but also numerically unstable since the covariance matrix is often ill-conditioned. We address the scalability issue via a novel approach without resorting to matrix approximations. By virtue of the so-called Markovian covariance functions, the associated covariance matrix can be invertible analytically, thereby improving both the efficiency and stability dramatically. Numerical experiments demonstrate that the proposed approach can handle large-scale problems where prior methods fail completely.","tags":["stochastic kriging","Gaussian process","gradient","big data","Markovian","covariance function"],"title":"A Scalable Approach to Enhancing Stochastic Kriging with Gradients","type":"publication"},{"authors":[],"categories":null,"content":"","date":1544608800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544608800,"objectID":"737c1533c19d87f6d7f40e1e431120db","permalink":"https://xiaoweiz.github.io/talk/wsc18-sk/","publishdate":"2019-06-03T20:52:16+08:00","relpermalink":"/talk/wsc18-sk/","section":"talk","summary":"It is known that incorporating gradient information can significantly enhance the prediction accuracy of stochastic kriging. However, such an enhancement cannot be scaled trivially to high-dimensional design space, since one needs to invert a large covariance matrix that captures the spatial correlations between the responses and the gradient estimates at the design points. Not only is the inversion computationally inefficient, but also numerically unstable since the covariance matrix is often ill-conditioned. We address the scalability issue via a novel approach without resorting to matrix approximations. By virtue of the so-called Markovian covariance functions, the associated covariance matrix can be invertible analytically, thereby improving both the efficiency and stability dramatically. Numerical experiments demonstrate that the proposed approach can handle large-scale problems where prior methods fail completely.","tags":["stochastic kriging","Markovian","covariance function","gradient","big data","Gaussian process"],"title":"A Scalable Approach to Enhancing Stochastic Kriging with Gradients","type":"talk"},{"authors":["Xiaocheng Li","Xiaowei Zhang","Zeyu Zheng"],"categories":[],"content":"","date":1544439959,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544439959,"objectID":"1cf32efdb335d00f184bbbcc1e4e6589","permalink":"https://xiaoweiz.github.io/publication/contextual-selection-high-dimension/","publishdate":"2019-06-03T21:56:02+08:00","relpermalink":"/publication/contextual-selection-high-dimension/","section":"publication","summary":"This paper considers the problem of ranking and selection with covariates (R\u0026S-C), which is ﬁrst introduced by Shen et al. (2017) and aims to identify a decision rule that stipulates the best alternative as a function of the observable covariates. We propose a general data-driven framework to accommodate (i) high-dimensional covariates and (ii) general (nonlinear) dependence between the mean performance of an alternative and the ceovariates. For both scenarios, we design new selection procedures and provide certain statistical guarantees, by leveraging the data-intensive environment and various statistical learning tools. The performances of our procedures are exhibited through simulation experiments.","tags":["ranking and selection","covariates","big data"],"title":"Data-Driven Ranking and Selection: High-dimensional Covariates and General Dependence","type":"publication"},{"authors":[],"categories":null,"content":"","date":1544439600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544439600,"objectID":"ae6d07af441b8b14b4cc8163e14f4354","permalink":"https://xiaoweiz.github.io/talk/wsc18-rs/","publishdate":"2019-06-03T20:50:32+08:00","relpermalink":"/talk/wsc18-rs/","section":"talk","summary":"This paper considers the problem of ranking and selection with covariates and aims to identify a decision rule that stipulates the best alternative as a function of the observable covariates. We propose a general data-driven framework to accommodate (i) high-dimensional covariates and (ii) general (nonlinear) dependence between the mean performance of an alternative and the covariates. For both scenarios, we design new selection procedures and provide certain statistical guarantees, by leveraging the data-intensive environment and various statistical learning tools. The performances of our procedures are exhibited through simulation experiments.","tags":["ranking and selection","covariates","big data"],"title":"Data-Driven Ranking and Selection: High-Dimensional Covariates and General Dependence","type":"talk"},{"authors":["Xiaowei Zhang","Peter W. Glynn"],"categories":[],"content":"","date":1541076903,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541076903,"objectID":"67469a7e83d276c879d4d49b19a3bf06","permalink":"https://xiaoweiz.github.io/publication/affine-jump-diffusion/","publishdate":"2019-06-03T20:55:03+08:00","relpermalink":"/publication/affine-jump-diffusion/","section":"publication","summary":"Affine jump-diffusions constitute a large class of continuous-time stochastic models that are particularly popular in finance and economics due to their analytical tractability. Methods for parameter estimation for such  processes require ergodicity in order establish consistency and asymptotic normality of the associated estimators. In this paper, we develop stochastic stability conditions for affine jump-diffusions, thereby providing the needed large-sample theoretical support for estimating such processes. We establish ergodicity for such models by imposing a ''strong mean reversion'' condition and a mild condition on the distribution of the jumps, i.e. the finiteness of a logarithmic moment. Exponential ergodicity holds if the jumps have a finite moment of a positive order. In addition, we prove strong laws of large numbers and functional central limit theorems for additive functionals for this class of models.","tags":["affine jump-diffusion","ergodicity"],"title":"Affine Jump-Diffusions: Stochastic Stability and Limit Theorems","type":"publication"},{"authors":[],"categories":null,"content":"","date":1528191000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528191000,"objectID":"0ac50a4ebc1bdc4a648330d4a55dab54","permalink":"https://xiaoweiz.github.io/talk/qingdao17/","publishdate":"2019-06-03T20:39:55+08:00","relpermalink":"/talk/qingdao17/","section":"talk","summary":"Operational decision making in service systems often depends largely on the characterization of the random fluctuations involved. Exogenous arrivals (e.g., customers, orders, etc.) represent a primary source of uncertainty and their stochastic behavior needs to be modeled carefully. In this talk, we will present a new statistical finding regarding the random fluctuations of the arrival process in large service systems, and propose a tractable model accordingly. When a service system under the new arrival model is scaled up, its dynamics is fundamentally different from that typical queueing analysis stipulates, and leads to a new staffing rule for managing the servers. At last, we will demonstrate via data-driven simulation that our staffing rule improves the system performance substantially in general.","tags":["Taylor's law","arrival data","heavy traffic","doubly stochastic Poisson process","overdispersion"],"title":"Fluctuation Scaling in Large Service Systems","type":"talk"},{"authors":["Haihui Shen","L. Jeff Hong","Xiaowei Zhang"],"categories":[],"content":"","date":1522490804,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522490804,"objectID":"0e8c560fd79e579f777fc4fe6a0a7e0d","permalink":"https://xiaoweiz.github.io/publication/stylized-model-stochastic-kriging/","publishdate":"2019-06-03T22:08:28+08:00","relpermalink":"/publication/stylized-model-stochastic-kriging/","section":"publication","summary":"Stochastic kriging is a popular metamodeling technique to approximate computationally expensive simulation models. However, it typically treats the simulation model as a black box in practice and often fails to capture the highly nonlinear response surfaces that arise from queueing simulations. We propose a simple, effective approach to improve the performance of stochastic kriging by incorporating stylized queueing models which contain useful information about the shape of the response surface. We provide several statistical tools to measure usefulness of the incorporated stylized models. We show that even a relatively crude stylized model can improve the prediction accuracy of stochastic kriging substantially.","tags":["Stochastic kriging","Gaussian process"],"title":"Enhancing Stochastic Kriging for Queueing Simulation with Stylized Models","type":"publication"},{"authors":[],"categories":null,"content":"","date":1522335600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522335600,"objectID":"3f3c920ab3b0fe8fa343fc65ad257374","permalink":"https://xiaoweiz.github.io/talk/tsinghuaie18/","publishdate":"2019-06-03T20:43:46+08:00","relpermalink":"/talk/tsinghuaie18/","section":"talk","summary":"A typical decision making problem in practice is to select the best from a finite set of alternatives, whose performances are unknown and can only be learned from sampling. This is referred to as the ranking and selection (R\u0026S) problem in simulation literature. Since the samples may be expensive to acquire, the R\u0026S problem is usually solved by designing a sampling procedure that ensures certain probability of correct selection with minimal samples. Motivated by the emerging popularity of personalized decision making in various areas such as healthcare, e-commerce, and wealth management as customer-speciﬁc data grows exponentially, in this talk we introduce a new paradigm called R\u0026S with covariates, where the best alternative is not universal but varies as a function of observable covariates. The goal is then to use sampling to compute a decision rule that specifies the best alternative for each subsequent individual after observing her covariates. We demonstrate the usefulness of our methodology via a case study in personalized medicine for selecting the best cancer treatment regimen. We show that by leveraging disease-related personal information, R\u0026S-C can improve substantially the expected quality-adjusted life years for some groups of patients through providing patient-speciﬁc treatment regimen.","tags":["ranking and selection","covariates"],"title":"Ranking and Selection with Covariates: Simulation for Personalized Decision Making","type":"talk"},{"authors":["Liang Ding","Xiaowei Zhang"],"categories":[],"content":"","date":1519985204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519985204,"objectID":"3309eccbc62478888aea4b71fc8e24a2","permalink":"https://xiaoweiz.github.io/publication/scalable-kriging/","publishdate":"2019-06-03T22:01:54+08:00","relpermalink":"/publication/scalable-kriging/","section":"publication","summary":"Stochastic kriging is a popular technique for simulation metamodeling due to its flexibility and analytical tractability. Its computational bottleneck is the inversion of a covariance matrix, which takes $O(n^3)$ time in general and becomes prohibitive for large $n$, where $n$ is the number of design points. Moreover, the covariance matrix is often ill-conditioned for large $n$, and thus the inversion is prone to numerical instability, resulting in erroneous parameter estimation and prediction. These two numerical issues preclude the use of stochastic kriging at a large scale. This paper presents a novel approach to address them. We construct a class of covariance functions, called Markovian covariance functions (MCFs), which have two properties: (i) the associated covariance matrices  can be inverted analytically, and (ii) the inverse matrices are sparse. With the use of MCFs, the inversion-related computational time is reduced to $O(n^2)$ in general, and can be further reduced by orders of magnitude with additional assumptions on the simulation errors and design points. The analytical invertibility also enhance the numerical stability dramatically. The key  in our approach is that we identify a general functional form of covariance functions that can induce sparsity in the corresponding inverse matrices. We also establish a connection between MCFs and linear ordinary differential equations. Such a connection provides a  flexible, principled approach to constructing a wide class of MCFs. Extensive numerical experiments demonstrate that stochastic kriging with MCFs can handle large-scale problems in an both computationally efficient and numerically stable manner. ","tags":["stochastic kriging","Gaussian process","Markovian","covariance function","big data"],"title":"Scalable Stochastic Kriging with Markovian Covariances","type":"publication"},{"authors":["Lu Zou","Xiaowei Zhang"],"categories":[],"content":"","date":1518083284,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518083284,"objectID":"19526a767a6ee67f00b34e84d6c6530c","permalink":"https://xiaoweiz.github.io/publication/kriging-inadequate/","publishdate":"2019-06-03T22:15:20+08:00","relpermalink":"/publication/kriging-inadequate/","section":"publication","summary":"Stochastic kriging is a popular metamodeling technique for representing the unknown response surface of a simulation model. However, the simulation model may be inadequate in the sense that there may be a non-negligible discrepancy between it and the real system of interest. Failing to account for the model discrepancy may conceivably result in erroneous prediction of the real system's performance and mislead the decision-making process. This paper proposes a metamodel that extends stochastic kriging to incorporate the model discrepancy. Both the simulation outputs and the real data are used to characterize the model discrepancy. The proposed metamodel can provably enhance the prediction of the real system's performance. We derive results for parameter estimation and experiment design, and demonstrate the advantage of the proposed metamodel relative to competing methods. Finally, we study the effect of Common Random Numbers (CRN). The use of CRN is well known to be detrimental to the prediction accuracy of stochastic kriging in general. By contrast, we show that the effect of CRN in the new context is substantially more complex. The use of CRN can be either detrimental or beneficial depending on the interplay between the magnitude of the observation errors and other parameters involved. ","tags":["stochastic kriging","Gaussian process","model inadequacy"],"title":"Stochastic Kriging for Inadequate Simulation Models","type":"publication"},{"authors":["Haihui Shen","L. Jeff Hong","Xiaowei Zhang"],"categories":[],"content":"","date":1512900404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512900404,"objectID":"5a950a173073b6f55928f2d65e1f99f1","permalink":"https://xiaoweiz.github.io/publication/contextual-selection-wsc/","publishdate":"2019-06-03T21:41:33+08:00","relpermalink":"/publication/contextual-selection-wsc/","section":"publication","summary":"We consider a new ranking and selection problem in which the performance of each alternative depends on some observable random covariates. The best alternative is thus not constant but depends on the values of the covariates. Assuming a linear model that relates the mean performance of an alternative and the covariates, we design selection procedures producing policies that represent the best alternative as a function in the covariates. We prove that  the selection procedures can provide certain statistical guarantee, which is defined via a nontrivial generalization of the concept of probability of correct selection that is widely used in the conventional ranking and selection setting.","tags":["ranking and selection","covariates"],"title":"Ranking and Selection with Covariates","type":"publication"},{"authors":[],"categories":null,"content":"","date":1512120600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512120600,"objectID":"e44fe38c6c55e90c53969041f0bac512","permalink":"https://xiaoweiz.github.io/talk/stanford17/","publishdate":"2019-06-03T20:34:43+08:00","relpermalink":"/talk/stanford17/","section":"talk","summary":"Stochastic kriging is a popular technique for simulation metamodeling due to its flexibility and analytical tractability. Its computational bottleneck is the inversion of a covariance matrix, which takes $O(n^3)$ time in general and becomes prohibitive for large $n$, where $n$ is the number of design points. Moreover, the covariance matrix is often ill-conditioned for large $n$, and thus the inversion is prone to numerical instability, resulting in erroneous parameter estimation and prediction. These two numerical issues preclude the use of stochastic kriging at a large scale. This paper presents a novel approach to address them. We construct a class of covariance functions, called Markovian covariance functions (MCFs), which have two properties: (i) the associated covariance matrices  can be inverted analytically, and (ii) the inverse matrices are sparse. With the use of MCFs, the inversion-related computational time is reduced to $O(n^2)$ in general, and can be further reduced by orders of magnitude with additional assumptions on the simulation errors and design points. The analytical invertibility also enhance the numerical stability dramatically. The key  in our approach is that we identify a general functional form of covariance functions that can induce sparsity in the corresponding inverse matrices. We also establish a connection between MCFs and linear ordinary differential equations. Such a connection provides a  flexible, principled approach to constructing a wide class of MCFs. Extensive numerical experiments demonstrate that stochastic kriging with MCFs can handle large-scale problems in an both computationally efficient and numerically stable manner.","tags":["stochastic kriging","Markovian","covariance function","big data","Gaussian process"],"title":"Scalable Stochastic Kriging with Markovian Covariances","type":"talk"},{"authors":[],"categories":null,"content":"","date":1498810800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498810800,"objectID":"4d8ee907ae489886f385b0755135c1bc","permalink":"https://xiaoweiz.github.io/talk/shanghaijiaotong17/","publishdate":"2019-06-03T20:41:55+08:00","relpermalink":"/talk/shanghaijiaotong17/","section":"talk","summary":"Simulation models are often computationally expensive to execute. Metamodeling is a technique to approximate simulation models to support fast performance evaluation and decision making. The basic concept is that the user executes the simulation model only at a small number of carefully selected ''design points''. A metamodel can be built to approximate the true response surface by interpolating the simulation outputs. The responses at other points are then predicted by the metamodel without running the simulation at all. However, existing metamodels generally treat the simulation model as a black box, discarding the structural properties of the response surface. Therefore, they often fail to capture highly nonlinear response surfaces. In this talk, new techniques will be discussed to address this issue, including stylized models and regularization in machine learning.","tags":["stochastic kriging","Gaussian process"],"title":"New Approaches for Enhancing Simulation Metamodeling","type":"talk"},{"authors":[],"categories":null,"content":"","date":1494516600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494516600,"objectID":"02afb7b8105b2286d3ccfd1af3570229","permalink":"https://xiaoweiz.github.io/talk/wuhan17/","publishdate":"2019-06-03T20:47:50+08:00","relpermalink":"/talk/wuhan17/","section":"talk","summary":"Affine jump-diffusion (AJD) processes constitute an important class of continuous time stochastic models that are widely used in finance and econometrics. For instance, many classic models in derivative pricing are special cases of AJD processes: the Ornstein-Uhlenbeck (OU) process (i.e. the Vasicek model), the square-root diffusion process, (i.e. the Cox-Ingersoll-Ross model), and the Heston stochastic volatility model. This class of models is flexible enough to capture various empirical attributes such as stochastic volatility and leverage effects. Its affine structure leads to significant tractability both for computing various expectations and probabilities. Most methods for parameter estimation (e.g. maximum likelihood estimation or generalized methods of moments) of this type of processes generally assume ergodicity in order establish consistency and asymptotic normality of the estimator. In this talk, we present several results on the stochastic stability of AJDs. We establish ergodicity of AJDs by imposing a ''mean reversion'' assumption and a mild condition on the distribution of the jumps, i.e. the finiteness of a logarithmic moment. As a stronger result, exponential ergodicity is proved if the jumps have a finite moment of a positive order. In addition, we prove strong laws of large numbers and functional central limit theorems for additive functional of this class of models. These limit theorems lay solid foundation for parameter estimation methods of AJDs.","tags":["affine jump-diffusion","ergodicity"],"title":"Affine Jump-Diffusions: Stochastic Stability and Limit Theorems","type":"talk"},{"authors":["Xiaowei Zhang","Liang Ding"],"categories":[],"content":"","date":1481364404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1481364404,"objectID":"2b4d0abdf813388790099e172b3f3c2a","permalink":"https://xiaoweiz.github.io/publication/robust-knowledge-gradient/","publishdate":"2019-06-03T21:38:29+08:00","relpermalink":"/publication/robust-knowledge-gradient/","section":"publication","summary":"We consider a Bayesian ranking and selection problem in the presence of input distribution uncertainty. The distribution uncertainty is treated from a robust perspective. A naive extension of the knowledge gradient (KG) policy fails to converge in the new robust setting. We propose several stationary policies that extend KG in various aspects. Numerical experiments show that the proposed policies have excellent performance in terms of both probability of correction selection and normalized opportunity cost.","tags":["ranking and selection","knowledge gradient","Bayesian","robust optimization"],"title":"Sequential Sampling for Bayesian Robust Ranking and Selection","type":"publication"},{"authors":["Xiaowei Zhang","Lu Zou"],"categories":[],"content":"","date":1480770044,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480770044,"objectID":"4867e87652d4a389f60b898a34c7c960","permalink":"https://xiaoweiz.github.io/publication/kriging-inadequate-wsc/","publishdate":"2019-06-03T21:00:44+08:00","relpermalink":"/publication/kriging-inadequate-wsc/","section":"publication","summary":"A simulation model is often used as a proxy for the real system of interest in a decision-making process. However, no simulation model is totally representative of the reality. The impact of the model inadequacy on the prediction of system performance should be carefully assessed. We propose a new metamodeling approach to simultaneously characterize both the simulation model and its model inadequacy. Our approach utilizes both simulation outputs and real data to predict system performance, and accounts for four types of uncertainty that arise from the unknown performance measure of the simulation model, simulation errors, unknown model inadequacy, and observation errors of the real system, respectively. Numerical results show that the new approach provides more accurate predictions in general.","tags":["stochastic kriging","model inadequacy","Gaussian process"],"title":"Simulation Metamodeling in the Presence of Model Inadequacy","type":"publication"},{"authors":["Xiaowei Zhang","Jose Blanchet","Kay Giesecke","Peter W. Glynn"],"categories":[],"content":"","date":1446553010,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446553010,"objectID":"4cbba5d6ab77e94059ef6648f221765f","permalink":"https://xiaoweiz.github.io/publication/affine-point-processes/","publishdate":"2015-11-03T20:16:50+08:00","relpermalink":"/publication/affine-point-processes/","section":"publication","summary":"We establish a central limit theorem and a large deviations principle for affine point processes, which are stochastic models of correlated event timing widely used in finance and economics. These limit results generate closed-form approximations to the distribution of an affine point process. They also facilitate the construction of an asymptotically optimal importance sampling estimator of tail probabilities. Numerical tests illustrate our results.","tags":["affine point process","affine jump-diffusion","large deviations","importance sampling","rare event simulation"],"title":"Affine Point Processes: Approximation and Efficient Simulation","type":"publication"},{"authors":["Xiaowei Zhang","L. Jeff Hong","Jiheng Zhang"],"categories":[],"content":"","date":1418206004,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1418206004,"objectID":"02a1aefeafa48695b610ec166057bbb5","permalink":"https://xiaoweiz.github.io/publication/scaling-arrival-wsc/","publishdate":"2019-06-03T22:05:47+08:00","relpermalink":"/publication/scaling-arrival-wsc/","section":"publication","summary":"The Poisson process has been an integral part of many models for the arrival process to a telephone call centers. However, several publications in recent years suggest the presence of a significant ''overdisperson'' relative to the Poisson process in real-life call center arrival data. In this paper, we study the overdispersion in the context of ''heavy traffic'' and identify a critical factor that characterizes the stochastic variability of the arrivals to their averages. We refer to such a factor as the scaling parameter and it potentially has a profound impact on the design of staffing rules. We propose an new model to capture the scaling parameter in this paper.","tags":["arrival data","Taylor's law","doubly stochastic Poisson process","overdispersion"],"title":"Scaling and Modeling of Call Center Arrivals","type":"publication"},{"authors":["Xiaowei Zhang"],"categories":[],"content":"","date":1386681379,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1386681379,"objectID":"fa05ca0dcf64537e632c7f1f4ad70ddc","permalink":"https://xiaoweiz.github.io/publication/bayesian-modeling-arrival-wsc/","publishdate":"2019-06-03T21:16:19+08:00","relpermalink":"/publication/bayesian-modeling-arrival-wsc/","section":"publication","summary":"The Poisson process has been widely used in the literature to model call center arrivals. In recent years, however, there have been empirical studies suggesting the call arrival process has significant non-Poisson characteristics. In this paper, we introduce a new doubly stochastic Poisson model for call center arrivals and develop a Bayesian approach for the parameter estimation via the Markov chain Monte Carlo method. The model can well capture the call arrival process as illustrated by a case study.","tags":["doubly stochastic Poisson process","Bayesian","arrival data","overdispersion","Markov chain Monte Carlo"],"title":"A Bayesian Approach for Modeling and Analysis of Call Center Arrivals","type":"publication"},{"authors":["Weiwei Fan","L. Jeff Hong","Xiaowei Zhang"],"categories":[],"content":"","date":1386670004,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1386670004,"objectID":"1086e430d2d668b248462020fb5ae668","permalink":"https://xiaoweiz.github.io/publication/robust-selection-wsc/","publishdate":"2019-06-03T21:05:35+08:00","relpermalink":"/publication/robust-selection-wsc/","section":"publication","summary":"Classical ranking-and-selection (R\u0026S) procedures cannot be applied directly to select the best decision in the presence of distributional ambiguity. In this paper we propose a robust selection of the best (RSB) framework which compares decisions based on their worst-case performances over a finite set of possible distributions and selects the decision with the best worst-case performance. To solve the RSB problems, we design a two-layer R\u0026S procedure under the indifference-zone formulation. The procedure identifies the worst-case distribution in the first stage and the best decision in the second. We prove the statistical validity of the two-layer procedure and test its performance numerically.","tags":["ranking and selection","robust optimization","input uncertainty"],"title":"Robust Selection of the Best","type":"publication"},{"authors":["Peter W. Glynn","Xiaowei Zhang"],"categories":[],"content":"","date":1291975604,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1291975604,"objectID":"35fbcb128568e73b786c842ddfe58fa1","permalink":"https://xiaoweiz.github.io/publication/regenerative-bootstrap/","publishdate":"2019-06-03T21:25:38+08:00","relpermalink":"/publication/regenerative-bootstrap/","section":"publication","summary":"We propose a new algorithm for identifying the duration of the initial transient for a regenerative stochastic process. The algorithm involves re-sampling of the simulated cycles, and therefore has a ''bootstrap'' flavor. The paper includes a derivation of the estimator for the duration of the transient that offers theoretical support for its validity, and provides a preliminary numerical investigation of the estimator's properties.","tags":["regenerative process","bootstrap","initial transient","steady state simulation"],"title":"A Regenerative Bootstrap Approach to Estimating the Initial Transient","type":"publication"},{"authors":["Xiaowei Zhang","Peter Glynn"],"categories":[],"content":"","date":1291888084,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1291888084,"objectID":"de7e5f38827560a9a3c20144b5104436","permalink":"https://xiaoweiz.github.io/publication/loss-process/","publishdate":"2019-06-03T21:23:06+08:00","relpermalink":"/publication/loss-process/","section":"publication","summary":"This paper is concerned with computing large deviations asymptotics for the loss process in a stylized queueing model that is fed by a Brownian input process. In addition, the dynamics of the queue, conditional on such a large deviation in the loss, is calculated. Finally, the paper computes the quasi-stationary distribution of the system and the corresponding dynamics, conditional on no loss occurring.","tags":["large deviations","reflected Brownian motion","local time"],"title":"On the Dynamics of a Finite Buffer Queue Conditioned on the Amount of Loss","type":"publication"},{"authors":["Xiaowei Zhang","Peter W. Glynn","Kay Giesecke","Jose Blanchet"],"categories":[],"content":"","date":1260439604,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1260439604,"objectID":"32cb7f5e3b8e345146da827a380b6fd6","permalink":"https://xiaoweiz.github.io/publication/rare-event-hawkes/","publishdate":"2019-06-03T21:19:27+08:00","relpermalink":"/publication/rare-event-hawkes/","section":"publication","summary":"In this paper we study  rare event simulation for the tail probability of an affine point process that generalizes the Hawkes process. By constructing a suitable exponential martingale, we are able to construct an importance sampling algorithm that is logarithmically efficient in the Gartner-Ellis asymptotic regime.","tags":["Hawkes process","affine point process","importance sampling","large deviations","rare event simulation"],"title":"Rare Event Simulation for a Generalized Hawkes Process","type":"publication"},{"authors":["Xiaowei Zhang","Jose Blanchet","Peter W. Glynn"],"categories":[],"content":"","date":1197281204,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1197281204,"objectID":"9df7cb0e9d78a34c2d00b56cd261e1f5","permalink":"https://xiaoweiz.github.io/publication/suboptimal-rare-event/","publishdate":"2019-06-03T22:18:24+08:00","relpermalink":"/publication/suboptimal-rare-event/","section":"publication","summary":"Much of the rare-event simulation literature is concerned with the development of asymptotically optimal algorithms. Because of the difficulties associated with applying these ideas to complex models, this paper focuses on sub-optimal procedures that can be shown to be much more efficient than conventional crude Monte Carlo. We provide two such examples, one based on ''repeated acceptance/rejection'' as a means of computing tail probabilities for hitting time random variables and the other based on filtered conditional Monte Carlo.","tags":["rare event simulation","importance sampling"],"title":"Efficient Suboptimal Rare-event Simulation","type":"publication"}]