<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Xiaowei Zhang</title>
    <link>https://xiaoweiz.github.io/project/</link>
    <description>Recent content in Projects on Xiaowei Zhang</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>&amp;copy; {year}</copyright>
    <lastBuildDate>Mon, 03 Jun 2019 21:26:25 +0800</lastBuildDate>
    
	    <atom:link href="https://xiaoweiz.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sampling-Based Optimization</title>
      <link>https://xiaoweiz.github.io/project/sampling-based-optimization/</link>
      <pubDate>Mon, 03 Jun 2019 21:26:25 +0800</pubDate>
      
      <guid>https://xiaoweiz.github.io/project/sampling-based-optimization/</guid>
      <description>&lt;p&gt;Modern stochastic systems often have a sophisticated structure. Their performance is generally not an analytical function of the decision variables, but a complex surface that can only be evaluated at discrete locations via noisy samples. Since the sampling process is often expensive, we would like to identify the optimal decision with minimal samples. Optimization via sampling is essentially a trade-off between &lt;em&gt;exploitation&lt;/em&gt;, which tends to sample more  at &amp;lsquo;&amp;lsquo;promising&amp;rsquo;&amp;rsquo; areas, and &lt;em&gt;exploration&lt;/em&gt;, which tends to sample more at &amp;lsquo;&amp;lsquo;uncharted&amp;rsquo;&amp;rsquo; areas. Hyperparameter tuning in machine learning is a modernized example of this paradigm of optimization.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simluation Metamodeling</title>
      <link>https://xiaoweiz.github.io/project/simulation-metamodeling/</link>
      <pubDate>Mon, 03 Jun 2019 20:22:36 +0800</pubDate>
      
      <guid>https://xiaoweiz.github.io/project/simulation-metamodeling/</guid>
      <description>&lt;p&gt;Simulation models are extensively used in a great variety of areas including health care, finance, manufacturing, logistics, supply chain management, telecommunication, etc. to facilitate related decision making processes. However, simulation models are usually computationally expensive to execute, which severely restricts the usefulness of simulation in settings such as real-time decision making and system optimization. Metamodeling is technique that has been actively developed in the simulation community, in order to alleviate the  inefficiency issue. The basic idea is that the user executes the simulation model only at a small number of carefully selected &amp;lsquo;&amp;lsquo;design points&amp;rsquo;&#39;. A metamodel, or model of the simulation model, can be built to approximate the true response surface by properly interpolating the simulation outputs. The response at other design points is then predicted by the metamodel without running simulation at all, thereby substantially reducing the computational costs.  The metamodel can be used to efficiently search for the optimal values of the design variables, even in real time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Arrival Data Modeling</title>
      <link>https://xiaoweiz.github.io/project/arrival-data-modeling/</link>
      <pubDate>Mon, 03 Jun 2019 19:25:36 +0800</pubDate>
      
      <guid>https://xiaoweiz.github.io/project/arrival-data-modeling/</guid>
      <description>&lt;p&gt;Operational decision making in service systems often depends largely on the characterization of the random fluctuations involved. Exogenous arrivals represent a primary source of uncertainty and their stochastic behavior needs to be modeled carefully. Recent empirical studies demonstrate that the arrival data usually exhibits a dynmacis that is substantially more sophisticated than the Poisson process model (and even the reneal process model), both of which are the underlying assumption of a wide variety of results in the queueing theory.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mathematical Finance</title>
      <link>https://xiaoweiz.github.io/project/mathematical-finance/</link>
      <pubDate>Mon, 03 Jun 2019 16:24:55 +0800</pubDate>
      
      <guid>https://xiaoweiz.github.io/project/mathematical-finance/</guid>
      <description>&lt;p&gt;Affine processes constitute an important class of continuous time stochastic models that are widely used in finance and econometrics due to their modeling flexibility and computational/analytical tractability. This class of models include affine jump-diffusions (AJDs) and affine point processes (APPs). Examples of AJDs include the Ornstein-Uhlenbeck (OU) process (i.e. the Vasicek model), the square-root diffusion process, (i.e. the Cox-Ingersoll-Ross model), and the Heston stochastic volatility model, all of which are classical models in dynamic asset pricing. On the other hand, examples of APPs include the Hawkes process and its multidimensional extensions, which was applied in credit risk modeling and has lately found important applications in high-frequency trading.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rare Event Analysis</title>
      <link>https://xiaoweiz.github.io/project/rare-event-analysis/</link>
      <pubDate>Mon, 03 Jun 2019 12:01:07 +0800</pubDate>
      
      <guid>https://xiaoweiz.github.io/project/rare-event-analysis/</guid>
      <description>&lt;p&gt;Rare events refer to those that occur with small probabilities but would have substantial impact when they do. Examples include meltdown of a communication network and credit default of a large financial institution. A typical approach to rare event analysis is the large deviations (LD) technique, which characterizes the rare event probability up to the correct logarithmic order of magnitude. To obtain a more accurate estimate, one often resorts to Monte Carlo (MC) simulation. But using the plain vanilla MC to estimate small probabilities requires an enormous number of samples due to the fact that the variance of the MC estimator is orders of magnitude larger than its mean. The LD technique can facilitate to develop importance sampling schemes that reduce the variance of the MC estimator dramatically.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
